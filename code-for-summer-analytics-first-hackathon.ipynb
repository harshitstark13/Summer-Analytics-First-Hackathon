{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d364752",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T20:30:09.783771Z",
     "iopub.status.busy": "2025-06-12T20:30:09.783355Z",
     "iopub.status.idle": "2025-06-12T20:30:11.862827Z",
     "shell.execute_reply": "2025-06-12T20:30:11.861691Z"
    },
    "papermill": {
     "duration": 2.085698,
     "end_time": "2025-06-12T20:30:11.864543",
     "exception": false,
     "start_time": "2025-06-12T20:30:09.778845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\n",
      "/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc6464",
   "metadata": {
    "papermill": {
     "duration": 0.001809,
     "end_time": "2025-06-12T20:30:11.869037",
     "exception": false,
     "start_time": "2025-06-12T20:30:11.867228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0bd0fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T20:30:11.874598Z",
     "iopub.status.busy": "2025-06-12T20:30:11.874149Z",
     "iopub.status.idle": "2025-06-12T20:31:18.316561Z",
     "shell.execute_reply": "2025-06-12T20:31:18.315609Z"
    },
    "papermill": {
     "duration": 66.448222,
     "end_time": "2025-06-12T20:31:18.319226",
     "exception": false,
     "start_time": "2025-06-12T20:30:11.871004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv')\n",
    "test = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv')\n",
    "ndvi_cols = [col for col in train.columns if col.endswith('_N')]\n",
    "\n",
    "# Map class to integer\n",
    "class_map = {'water': 0, 'impervious': 1, 'farm': 2, 'forest': 3, 'grass': 4, 'orchard': 5}\n",
    "inv_class_map = {v: k for k, v in class_map.items()}\n",
    "train['class_code'] = train['class'].map(class_map)\n",
    "\n",
    "# Upsample minority classes\n",
    "def balance_classes(df):\n",
    "    major = df[df['class'] == 'forest']\n",
    "    dfs = [major]\n",
    "    for cls in ['farm', 'impervious', 'grass', 'water', 'orchard']:\n",
    "        minor = df[df['class'] == cls]\n",
    "        upsampled = resample(minor, replace=True, n_samples=len(major)//2, random_state=42)\n",
    "        dfs.append(upsampled)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "train = balance_classes(train)\n",
    "\n",
    "# Impute and feature engineer\n",
    "def feature_engineer(df):\n",
    "    X = df[ndvi_cols]\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    X_imp = imputer.fit_transform(X)\n",
    "\n",
    "    feats = pd.DataFrame()\n",
    "    feats['mean'] = X_imp.mean(axis=1)\n",
    "    feats['std'] = X_imp.std(axis=1)\n",
    "    feats['min'] = X_imp.min(axis=1)\n",
    "    feats['max'] = X_imp.max(axis=1)\n",
    "    feats['range'] = feats['max'] - feats['min']\n",
    "    feats['skew'] = skew(X_imp, axis=1)\n",
    "    feats['kurtosis'] = kurtosis(X_imp, axis=1)\n",
    "    feats['trend'] = (X_imp[:, -1] - X_imp[:, 0]) / (X_imp.shape[1])\n",
    "\n",
    "    # Seasonal features\n",
    "    feats['early_season'] = X_imp[:, :9].mean(axis=1)\n",
    "    feats['mid_season'] = X_imp[:, 9:18].mean(axis=1)\n",
    "    feats['late_season'] = X_imp[:, 18:].mean(axis=1)\n",
    "    \n",
    "    return feats\n",
    "\n",
    "X_train = feature_engineer(train)\n",
    "X_test = feature_engineer(test)\n",
    "y_train = train['class_code']\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model: Tuned XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.9,\n",
    "    objective='multi:softprob',\n",
    "    num_class=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb.predict(X_test_scaled)\n",
    "preds_labels = [inv_class_map[i] for i in preds]\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'class': preds_labels\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Final submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5898af",
   "metadata": {
    "papermill": {
     "duration": 0.001852,
     "end_time": "2025-06-12T20:31:18.323294",
     "exception": false,
     "start_time": "2025-06-12T20:31:18.321442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee5635c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T20:31:18.329353Z",
     "iopub.status.busy": "2025-06-12T20:31:18.329054Z",
     "iopub.status.idle": "2025-06-12T20:34:03.846686Z",
     "shell.execute_reply": "2025-06-12T20:34:03.845537Z"
    },
    "papermill": {
     "duration": 165.526133,
     "end_time": "2025-06-12T20:34:03.851605",
     "exception": false,
     "start_time": "2025-06-12T20:31:18.325472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/107974898.py:57: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_mean = pd.DataFrame(X_imp).rolling(window=w, axis=1).mean().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:58: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_std = pd.DataFrame(X_imp).rolling(window=w, axis=1).std().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:57: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_mean = pd.DataFrame(X_imp).rolling(window=w, axis=1).mean().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:58: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_std = pd.DataFrame(X_imp).rolling(window=w, axis=1).std().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:57: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_mean = pd.DataFrame(X_imp).rolling(window=w, axis=1).mean().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:58: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_std = pd.DataFrame(X_imp).rolling(window=w, axis=1).std().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:57: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_mean = pd.DataFrame(X_imp).rolling(window=w, axis=1).mean().mean(axis=1)\n",
      "/tmp/ipykernel_13/107974898.py:58: FutureWarning: Support for axis=1 in DataFrame.rolling is deprecated and will be removed in a future version. Use obj.T.rolling(...) instead\n",
      "  roll_std = pd.DataFrame(X_imp).rolling(window=w, axis=1).std().mean(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 31159, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.829665\n",
      "[LightGBM] [Info] Start training from score -1.829665\n",
      "[LightGBM] [Info] Start training from score -1.829665\n",
      "[LightGBM] [Info] Start training from score -1.621189\n",
      "[LightGBM] [Info] Start training from score -1.829665\n",
      "[LightGBM] [Info] Start training from score -1.829665\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "✅ Ensemble submission created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Load Data\n",
    "train = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv')\n",
    "test = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv')\n",
    "ndvi_cols = [col for col in train.columns if col.endswith('_N')]\n",
    "\n",
    "# Label Encoding\n",
    "class_map = {'water': 0, 'impervious': 1, 'farm': 2, 'forest': 3, 'grass': 4, 'orchard': 5}\n",
    "inv_class_map = {v: k for k, v in class_map.items()}\n",
    "train['class_code'] = train['class'].map(class_map)\n",
    "\n",
    "# Balanced Sampling\n",
    "def balance(df):\n",
    "    dfs = [df[df['class'] == 'forest']]\n",
    "    for cls in ['farm', 'impervious', 'grass', 'water', 'orchard']:\n",
    "        d = df[df['class'] == cls]\n",
    "        dfs.append(resample(d, replace=True, n_samples=5000, random_state=42))\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "train = balance(train)\n",
    "\n",
    "# Feature Engineering\n",
    "def features(df):\n",
    "    X = df[ndvi_cols].copy()\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    X_imp = imputer.fit_transform(X)\n",
    "\n",
    "    df_feat = pd.DataFrame()\n",
    "    df_feat['mean'] = X_imp.mean(axis=1)\n",
    "    df_feat['std'] = X_imp.std(axis=1)\n",
    "    df_feat['min'] = X_imp.min(axis=1)\n",
    "    df_feat['max'] = X_imp.max(axis=1)\n",
    "    df_feat['range'] = df_feat['max'] - df_feat['min']\n",
    "    df_feat['skew'] = skew(X_imp, axis=1)\n",
    "    df_feat['kurt'] = kurtosis(X_imp, axis=1)\n",
    "    df_feat['trend'] = (X_imp[:, -1] - X_imp[:, 0]) / X_imp.shape[1]\n",
    "\n",
    "    df_feat['early'] = X_imp[:, :9].mean(axis=1)\n",
    "    df_feat['mid'] = X_imp[:, 9:18].mean(axis=1)\n",
    "    df_feat['late'] = X_imp[:, 18:].mean(axis=1)\n",
    "\n",
    "    # Rolling window stats\n",
    "    for w in [3, 5]:\n",
    "        roll_mean = pd.DataFrame(X_imp).rolling(window=w, axis=1).mean().mean(axis=1)\n",
    "        roll_std = pd.DataFrame(X_imp).rolling(window=w, axis=1).std().mean(axis=1)\n",
    "        df_feat[f'roll{w}_mean'] = roll_mean\n",
    "        df_feat[f'roll{w}_std'] = roll_std\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "# Prepare data\n",
    "X_train = features(train)\n",
    "y_train = train['class_code']\n",
    "X_test = features(test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model Stack\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate=0.03, max_depth=6, subsample=0.9, colsample_bytree=0.9, objective='multi:softmax', use_label_encoder=False, eval_metric='mlogloss')\n",
    "lgb = LGBMClassifier(n_estimators=500, learning_rate=0.03, max_depth=6)\n",
    "cat = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.03, verbose=0)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('xgb', xgb), ('lgb', lgb), ('cat', cat)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ensemble.predict(X_test_scaled)\n",
    "y_label = [inv_class_map[i] for i in y_pred]\n",
    "\n",
    "# Submission\n",
    "sub = pd.DataFrame({'ID': test['ID'], 'class': y_label})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Ensemble submission created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12585144,
     "sourceId": 104491,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 240.28288,
   "end_time": "2025-06-12T20:34:04.879787",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T20:30:04.596907",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
